{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19407528740524\t0.079775995626213\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- require 'loadcaffe';\n",
    "-- require 'image';\n",
    "-- require 'cunn';\n",
    "-- require 'cudnn';\n",
    "require 'nngraph';\n",
    "\n",
    "function createFullModel(B_model, C_model)\n",
    "\tlocal image_feat1 = nn.Identity()();\n",
    "\tlocal image_feat2 = nn.Identity()();\n",
    "\tlocal image_feat3 = nn.Identity()();\n",
    "\tlocal question = nn.Identity()();\n",
    "\n",
    "\tlocal confidence = B_model({question, image_feat3});\n",
    "\tlocal scores = C_model({image_feat1, image_feat2, question, confidence});\n",
    "\t\n",
    "\tnngraph.annotateNodes();\n",
    "\treturn nn.gModule({image_feat1, image_feat2, image_feat3, question}, {scores});\n",
    "end\n",
    "\n",
    "B_model = torch.load('B_model_nn.t7')\n",
    "C_model = torch.load('C_model.t7')\n",
    "\n",
    "-- B_model:cuda()\n",
    "B_model:evaluate()\n",
    "\n",
    "-- C_model:cuda()\n",
    "C_model:evaluate()\n",
    "\n",
    "BC_model = createFullModel(B_model, C_model)\n",
    "-- ABC_model = createFullModel(A_model, B_model, C_model, encoders);\n",
    "\n",
    "-- put all models on cuda and in evalaute mode\n",
    "\n",
    "-- BC_model:cuda()\n",
    "BC_model:double()\n",
    "-- BC_model:evaluate()\n",
    "\n",
    "-- Use a typical generic gradient update function\n",
    "function trainStep(model, input, target, criterion, learningRate)\n",
    "    local pred = model:forward(input)\n",
    "    local err = criterion:forward(pred, target)\n",
    "    local gradCriterion = criterion:backward(pred, target)\n",
    "\n",
    "    model:zeroGradParameters()\n",
    "    model:backward(input, {gradCriterion[1], gradCriterion[2]})\n",
    "    C_model:updateParameters(learningRate)\n",
    "\n",
    "--     print('pred = ', pred[1][1], pred[2][1])\n",
    "    print('err = ', err)\n",
    "end\n",
    "\n",
    "-- read preprocessed feature vectors\n",
    "feat_vecs = torch.load('feat_vecs.t7')\n",
    "\n",
    "-- generate random label\n",
    "-- label = torch.bernoulli() + 1\n",
    "label = 2\n",
    "target = 2*label-3\n",
    "\n",
    "-- generate dummy data\n",
    "image_feat = {}\n",
    "image_feat[1] = feat_vecs[10]\n",
    "image_feat[2] = feat_vecs[20]\n",
    "image_feat[3] = image_feat[label]:clone()\n",
    "\n",
    "-- generate a dummy question\n",
    "ques = torch.Tensor(42):fill(0)\n",
    "ques[3] = 1\n",
    "\n",
    "-- dummy forward propagation through the model\n",
    "output = BC_model:forward({image_feat[1], image_feat[2], image_feat[3], ques})\n",
    "print(output[1][1], output[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- for i = 1, #BC_model.modules do\n",
    "--     mod = BC_model.modules[i]\n",
    "--     print(mod.train)\n",
    "-- end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0.37385128303145\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "err = \t0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_old = B_model.modules[2].modules[3].weight:clone()\n",
    "wc1_old = C_model.modules[8].modules[1].weight:clone()\n",
    "wc2_old = C_model.modules[8].modules[3].weight:clone()\n",
    "\n",
    "-- dummy training\n",
    "crit = nn.MarginRankingCriterion(0.1)\n",
    "lr = 1\n",
    "print(target)\n",
    "for i = 1, 10 do\n",
    "    trainStep(BC_model, {image_feat[1], image_feat[2], image_feat[3], ques}, target, crit, lr)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wb = B_model.modules[2].modules[3].weight:clone()\n",
    "wc1 = C_model.modules[8].modules[1].weight:clone()\n",
    "wc2 = C_model.modules[8].modules[3].weight:clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017086426887453\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0\t\n",
       "0\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_diff = wb_old - wb\n",
    "wc1_diff = wc1_old - wc1\n",
    "wc2_diff = wc2_old - wc2\n",
    "print(torch.max(torch.abs(wb_diff)))\n",
    "print(torch.max(torch.abs(wc1_diff)))\n",
    "print(torch.max(torch.abs(wc2_diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
