Loading pretrained model... done
Training with snapshotting disabled... 
Testing... average test_loss = 0.96024951022942, average test_pred_err = 0.487
iter 1, lr: 2, attr_lr: 0.5, batch_loss: 0.97407519830504, train_err: 0.47265625, grad_norm: 0.058062062329005
iter 2, lr: 2, attr_lr: 0.5, batch_loss: 0.90223683617644, train_err: 0.49609375, grad_norm: 0.027041640106886
iter 3, lr: 2, attr_lr: 0.5, batch_loss: 0.8625079706708, train_err: 0.48828125, grad_norm: 0.025514007101316
iter 4, lr: 2, attr_lr: 0.5, batch_loss: 0.86814461325329, train_err: 0.482421875, grad_norm: 0.023285171272917
iter 5, lr: 2, attr_lr: 0.5, batch_loss: 0.86758072856657, train_err: 0.505859375, grad_norm: 0.023846088520257
iter 6, lr: 2, attr_lr: 0.5, batch_loss: 0.81670313294043, train_err: 0.478515625, grad_norm: 0.022274051416899
iter 7, lr: 2, attr_lr: 0.5, batch_loss: 0.89391907582845, train_err: 0.521484375, grad_norm: 0.025140066018018
iter 8, lr: 2, attr_lr: 0.5, batch_loss: 0.79551441190731, train_err: 0.470703125, grad_norm: 0.022976233780655
iter 9, lr: 2, attr_lr: 0.5, batch_loss: 0.82422486849628, train_err: 0.490234375, grad_norm: 0.023019060141871
iter 10, lr: 2, attr_lr: 0.5, batch_loss: 0.79205834062398, train_err: 0.466796875, grad_norm: 0.021772549075041
iter 11, lr: 2, attr_lr: 0.5, batch_loss: 0.74283107245541, train_err: 0.453125, grad_norm: 0.019393114856502
iter 12, lr: 2, attr_lr: 0.5, batch_loss: 0.70979429328067, train_err: 0.455078125, grad_norm: 0.02030059037576
iter 13, lr: 2, attr_lr: 0.5, batch_loss: 0.72628656809975, train_err: 0.4375, grad_norm: 0.01911472826243
iter 14, lr: 2, attr_lr: 0.5, batch_loss: 0.68776486683078, train_err: 0.42578125, grad_norm: 0.019160660740376
iter 15, lr: 2, attr_lr: 0.5, batch_loss: 0.72865610749084, train_err: 0.451171875, grad_norm: 0.020177733391391
iter 16, lr: 2, attr_lr: 0.5, batch_loss: 0.72690904137859, train_err: 0.48046875, grad_norm: 0.02054688714809
iter 17, lr: 2, attr_lr: 0.5, batch_loss: 0.652745396256, train_err: 0.419921875, grad_norm: 0.019075586068238
iter 18, lr: 2, attr_lr: 0.5, batch_loss: 0.70669101349786, train_err: 0.46875, grad_norm: 0.019373064158992
iter 19, lr: 2, attr_lr: 0.5, batch_loss: 0.7367252780758, train_err: 0.4921875, grad_norm: 0.019148068276223
iter 20, lr: 2, attr_lr: 0.5, batch_loss: 0.71840183548863, train_err: 0.474609375, grad_norm: 0.021325679901536
iter 21, lr: 2, attr_lr: 0.5, batch_loss: 0.72139538487783, train_err: 0.48046875, grad_norm: 0.019996899263131
iter 22, lr: 2, attr_lr: 0.5, batch_loss: 0.69127975465024, train_err: 0.45703125, grad_norm: 0.019255871152348
iter 23, lr: 2, attr_lr: 0.5, batch_loss: 0.66528360866598, train_err: 0.4296875, grad_norm: 0.017629308589037
iter 24, lr: 2, attr_lr: 0.5, batch_loss: 0.67397874975844, train_err: 0.466796875, grad_norm: 0.01932907959786
iter 25, lr: 2, attr_lr: 0.5, batch_loss: 0.67019878100598, train_err: 0.423828125, grad_norm: 0.017940867522596
iter 26, lr: 2, attr_lr: 0.5, batch_loss: 0.68773085311488, train_err: 0.455078125, grad_norm: 0.018809506638303
iter 27, lr: 2, attr_lr: 0.5, batch_loss: 0.64545195402121, train_err: 0.4140625, grad_norm: 0.017277389463852
iter 28, lr: 2, attr_lr: 0.5, batch_loss: 0.66218340933737, train_err: 0.439453125, grad_norm: 0.017968356604912
iter 29, lr: 2, attr_lr: 0.5, batch_loss: 0.6827119322657, train_err: 0.451171875, grad_norm: 0.019629999794318
iter 30, lr: 2, attr_lr: 0.5, batch_loss: 0.65678043834208, train_err: 0.421875, grad_norm: 0.01883003836252
iter 31, lr: 2, attr_lr: 0.5, batch_loss: 0.66947522459568, train_err: 0.41796875, grad_norm: 0.018803789575712
iter 32, lr: 2, attr_lr: 0.5, batch_loss: 0.59727090693833, train_err: 0.373046875, grad_norm: 0.016807014224993
iter 33, lr: 2, attr_lr: 0.5, batch_loss: 0.61280736040304, train_err: 0.375, grad_norm: 0.016984635822492
iter 34, lr: 2, attr_lr: 0.5, batch_loss: 0.64614811840257, train_err: 0.416015625, grad_norm: 0.017755984146074
iter 35, lr: 2, attr_lr: 0.5, batch_loss: 0.64474762217978, train_err: 0.396484375, grad_norm: 0.017252039818019
iter 36, lr: 2, attr_lr: 0.5, batch_loss: 0.63599794000253, train_err: 0.390625, grad_norm: 0.016681139685194
iter 37, lr: 2, attr_lr: 0.5, batch_loss: 0.6537953320359, train_err: 0.43359375, grad_norm: 0.018437261930273
iter 38, lr: 2, attr_lr: 0.5, batch_loss: 0.60714615196621, train_err: 0.376953125, grad_norm: 0.016456029783111
iter 39, lr: 2, attr_lr: 0.5, batch_loss: 0.62641385102469, train_err: 0.427734375, grad_norm: 0.015638412634953
iter 40, lr: 2, attr_lr: 0.5, batch_loss: 0.66123625951885, train_err: 0.4453125, grad_norm: 0.018048602692053
iter 41, lr: 2, attr_lr: 0.5, batch_loss: 0.61714825697294, train_err: 0.380859375, grad_norm: 0.016863364103334
iter 42, lr: 2, attr_lr: 0.5, batch_loss: 0.59966261934643, train_err: 0.416015625, grad_norm: 0.016931690714817
iter 43, lr: 2, attr_lr: 0.5, batch_loss: 0.63716638646024, train_err: 0.447265625, grad_norm: 0.017646907324092
iter 44, lr: 2, attr_lr: 0.5, batch_loss: 0.61698743407407, train_err: 0.392578125, grad_norm: 0.017284057335994
iter 45, lr: 2, attr_lr: 0.5, batch_loss: 0.60466782540172, train_err: 0.373046875, grad_norm: 0.017550655497366
iter 46, lr: 2, attr_lr: 0.5, batch_loss: 0.61061269577479, train_err: 0.376953125, grad_norm: 0.016825101101101
iter 47, lr: 2, attr_lr: 0.5, batch_loss: 0.62444445359799, train_err: 0.392578125, grad_norm: 0.01641627662254
iter 48, lr: 2, attr_lr: 0.5, batch_loss: 0.57681750189555, train_err: 0.3828125, grad_norm: 0.015340249145432
iter 49, lr: 2, attr_lr: 0.5, batch_loss: 0.6242257641666, train_err: 0.388671875, grad_norm: 0.01633285201075
iter 50, lr: 2, attr_lr: 0.5, batch_loss: 0.59600899210136, train_err: 0.365234375, grad_norm: 0.017273298109206
Testing... average test_loss = 0.62170413441892, average test_pred_err = 0.401
iter 51, lr: 2, attr_lr: 0.5, batch_loss: 0.61667428467685, train_err: 0.396484375, grad_norm: 0.016969250296997
iter 52, lr: 2, attr_lr: 0.5, batch_loss: 0.66726310648284, train_err: 0.40625, grad_norm: 0.016678156082438
iter 53, lr: 2, attr_lr: 0.5, batch_loss: 0.5965007815773, train_err: 0.380859375, grad_norm: 0.015925229414181
iter 54, lr: 2, attr_lr: 0.5, batch_loss: 0.60514098008555, train_err: 0.38671875, grad_norm: 0.017501992660041
iter 55, lr: 2, attr_lr: 0.5, batch_loss: 0.58185058027485, train_err: 0.37109375, grad_norm: 0.015447856469008
iter 56, lr: 2, attr_lr: 0.5, batch_loss: 0.59188806442775, train_err: 0.361328125, grad_norm: 0.016295916011331
iter 57, lr: 2, attr_lr: 0.5, batch_loss: 0.58429271293985, train_err: 0.40234375, grad_norm: 0.015857493914928
iter 58, lr: 2, attr_lr: 0.5, batch_loss: 0.61151295700072, train_err: 0.388671875, grad_norm: 0.017792200507867
iter 59, lr: 2, attr_lr: 0.5, batch_loss: 0.60010376829735, train_err: 0.37890625, grad_norm: 0.015997366273006
iter 60, lr: 2, attr_lr: 0.5, batch_loss: 0.62100011581803, train_err: 0.39453125, grad_norm: 0.014700084117857
iter 61, lr: 2, attr_lr: 0.5, batch_loss: 0.61214376826242, train_err: 0.3984375, grad_norm: 0.015147724081882
iter 62, lr: 2, attr_lr: 0.5, batch_loss: 0.56582314519548, train_err: 0.35546875, grad_norm: 0.01713901207219
iter 63, lr: 2, attr_lr: 0.5, batch_loss: 0.56151994402801, train_err: 0.349609375, grad_norm: 0.015903974438513
iter 64, lr: 2, attr_lr: 0.5, batch_loss: 0.55923672478524, train_err: 0.33984375, grad_norm: 0.014782933394734
iter 65, lr: 2, attr_lr: 0.5, batch_loss: 0.59062196289562, train_err: 0.361328125, grad_norm: 0.015021008907241
iter 66, lr: 2, attr_lr: 0.5, batch_loss: 0.56780368220635, train_err: 0.349609375, grad_norm: 0.015924786135058
iter 67, lr: 2, attr_lr: 0.5, batch_loss: 0.58327535176692, train_err: 0.373046875, grad_norm: 0.015507255972306
iter 68, lr: 2, attr_lr: 0.5, batch_loss: 0.59387991183991, train_err: 0.369140625, grad_norm: 0.016050074219773
iter 69, lr: 2, attr_lr: 0.5, batch_loss: 0.58796447438755, train_err: 0.365234375, grad_norm: 0.016298856479111
iter 70, lr: 2, attr_lr: 0.5, batch_loss: 0.5672064098509, train_err: 0.31640625, grad_norm: 0.013418401284364
iter 71, lr: 2, attr_lr: 0.5, batch_loss: 0.57324049970906, train_err: 0.328125, grad_norm: 0.016382924106406
iter 72, lr: 2, attr_lr: 0.5, batch_loss: 0.54892227972827, train_err: 0.337890625, grad_norm: 0.01417411599197
iter 73, lr: 2, attr_lr: 0.5, batch_loss: 0.58498058698216, train_err: 0.375, grad_norm: 0.014511978610606
iter 74, lr: 2, attr_lr: 0.5, batch_loss: 0.56544379505395, train_err: 0.353515625, grad_norm: 0.015673780162807
iter 75, lr: 2, attr_lr: 0.5, batch_loss: 0.59055677396286, train_err: 0.3671875, grad_norm: 0.015172988027239
iter 76, lr: 2, attr_lr: 0.5, batch_loss: 0.55109877406837, train_err: 0.33984375, grad_norm: 0.015191752523709
