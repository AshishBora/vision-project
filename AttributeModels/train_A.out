Loading pretrained model... done
Creating Full model... done
Reading features and labels... done
Training with snapshotting enabled... 
Testing... test_loss = 1.0839274745227, test_pred_err = 0.33
Iteration no. 1, lr = 0.0001, batch_loss = 0.87929339477142, train_err = 0.287109375
Iteration no. 2, lr = 0.0001, batch_loss = 0.67705020844886, train_err = 0.26953125
Iteration no. 3, lr = 0.0001, batch_loss = 0.52570668399066, train_err = 0.212890625
Iteration no. 4, lr = 0.0001, batch_loss = 0.38179149717119, train_err = 0.150390625
Iteration no. 5, lr = 0.0001, batch_loss = 0.46802396309788, train_err = 0.1796875
Iteration no. 6, lr = 0.0001, batch_loss = 0.35121036072239, train_err = 0.14453125
Iteration no. 7, lr = 0.0001, batch_loss = 0.40061997665325, train_err = 0.18359375
Iteration no. 8, lr = 0.0001, batch_loss = 0.38361471151377, train_err = 0.171875
Iteration no. 9, lr = 0.0001, batch_loss = 0.27829925319908, train_err = 0.126953125
Iteration no. 10, lr = 0.0001, batch_loss = 0.30281956078732, train_err = 0.13671875
Iteration no. 11, lr = 0.0001, batch_loss = 0.33521641555102, train_err = 0.14453125
Iteration no. 12, lr = 0.0001, batch_loss = 0.32743968366978, train_err = 0.138671875
Iteration no. 13, lr = 0.0001, batch_loss = 0.2998602990785, train_err = 0.123046875
Iteration no. 14, lr = 0.0001, batch_loss = 0.34562427054365, train_err = 0.158203125
Iteration no. 15, lr = 0.0001, batch_loss = 0.37519965693134, train_err = 0.16796875
Iteration no. 16, lr = 0.0001, batch_loss = 0.3729930414102, train_err = 0.1640625
Iteration no. 17, lr = 0.0001, batch_loss = 0.38547634232388, train_err = 0.189453125
Iteration no. 18, lr = 0.0001, batch_loss = 0.33036580785054, train_err = 0.15234375
Iteration no. 19, lr = 0.0001, batch_loss = 0.37937350739585, train_err = 0.16796875
Iteration no. 20, lr = 0.0001, batch_loss = 0.34586981081102, train_err = 0.1640625
Iteration no. 21, lr = 0.0001, batch_loss = 0.31520841162196, train_err = 0.126953125
Iteration no. 22, lr = 0.0001, batch_loss = 0.34207231678564, train_err = 0.15625
Iteration no. 23, lr = 0.0001, batch_loss = 0.30193124630951, train_err = 0.1328125
Iteration no. 24, lr = 0.0001, batch_loss = 0.35101261542878, train_err = 0.16015625
Iteration no. 25, lr = 0.0001, batch_loss = 0.35069732988932, train_err = 0.15234375
Iteration no. 26, lr = 0.0001, batch_loss = 0.33644000449506, train_err = 0.162109375
Iteration no. 27, lr = 0.0001, batch_loss = 0.35062527521201, train_err = 0.158203125
Iteration no. 28, lr = 0.0001, batch_loss = 0.39119209890835, train_err = 0.166015625
Iteration no. 29, lr = 0.0001, batch_loss = 0.3249821907925, train_err = 0.140625
Iteration no. 30, lr = 0.0001, batch_loss = 0.32527307306612, train_err = 0.150390625
Iteration no. 31, lr = 0.0001, batch_loss = 0.34149967289021, train_err = 0.134765625
Iteration no. 32, lr = 0.0001, batch_loss = 0.36240722863038, train_err = 0.1640625
Iteration no. 33, lr = 0.0001, batch_loss = 0.32144495646857, train_err = 0.142578125
Iteration no. 34, lr = 0.0001, batch_loss = 0.32442960249204, train_err = 0.154296875
Iteration no. 35, lr = 0.0001, batch_loss = 0.28648824383804, train_err = 0.123046875
Iteration no. 36, lr = 0.0001, batch_loss = 0.32323357600243, train_err = 0.14453125
Iteration no. 37, lr = 0.0001, batch_loss = 0.2938532208747, train_err = 0.1171875
Iteration no. 38, lr = 0.0001, batch_loss = 0.34571318994264, train_err = 0.14453125
Iteration no. 39, lr = 0.0001, batch_loss = 0.34473660983827, train_err = 0.140625
Iteration no. 40, lr = 0.0001, batch_loss = 0.35121433735978, train_err = 0.134765625
Iteration no. 41, lr = 0.0001, batch_loss = 0.29092413960928, train_err = 0.125
Iteration no. 42, lr = 0.0001, batch_loss = 0.30171409582462, train_err = 0.146484375
Iteration no. 43, lr = 0.0001, batch_loss = 0.30576351355755, train_err = 0.138671875
Iteration no. 44, lr = 0.0001, batch_loss = 0.33362722335142, train_err = 0.126953125
Iteration no. 45, lr = 0.0001, batch_loss = 0.30202758042846, train_err = 0.140625
Iteration no. 46, lr = 0.0001, batch_loss = 0.31637373734709, train_err = 0.1484375
Iteration no. 47, lr = 0.0001, batch_loss = 0.28713414459404, train_err = 0.125
Iteration no. 48, lr = 0.0001, batch_loss = 0.24093386267924, train_err = 0.095703125
Iteration no. 49, lr = 0.0001, batch_loss = 0.35677325941565, train_err = 0.138671875
Iteration no. 50, lr = 0.0001, batch_loss = 0.33331592183589, train_err = 0.158203125
Testing... test_loss = 0.31279840060443, test_pred_err = 0.136
Iteration no. 51, lr = 0.0001, batch_loss = 0.30343239654446, train_err = 0.1328125
Iteration no. 52, lr = 0.0001, batch_loss = 0.29675203290793, train_err = 0.1328125
Iteration no. 53, lr = 0.0001, batch_loss = 0.31818680628136, train_err = 0.140625
Iteration no. 54, lr = 0.0001, batch_loss = 0.26604824309106, train_err = 0.115234375
Iteration no. 55, lr = 0.0001, batch_loss = 0.24346628471447, train_err = 0.119140625
Iteration no. 56, lr = 0.0001, batch_loss = 0.30453511380866, train_err = 0.1328125
Iteration no. 57, lr = 0.0001, batch_loss = 0.27563149141293, train_err = 0.119140625
Iteration no. 58, lr = 0.0001, batch_loss = 0.32019087911859, train_err = 0.140625
Iteration no. 59, lr = 0.0001, batch_loss = 0.2759535842082, train_err = 0.125
Iteration no. 60, lr = 0.0001, batch_loss = 0.27116366373799, train_err = 0.119140625
Iteration no. 61, lr = 0.0001, batch_loss = 0.27567474417742, train_err = 0.12109375
Iteration no. 62, lr = 0.0001, batch_loss = 0.31265278000826, train_err = 0.12890625
Iteration no. 63, lr = 0.0001, batch_loss = 0.28833447466688, train_err = 0.109375
Iteration no. 64, lr = 0.0001, batch_loss = 0.26447994404641, train_err = 0.1171875
Iteration no. 65, lr = 0.0001, batch_loss = 0.3374900203803, train_err = 0.140625
Iteration no. 66, lr = 0.0001, batch_loss = 0.28746339469438, train_err = 0.125
Iteration no. 67, lr = 0.0001, batch_loss = 0.32353025694598, train_err = 0.142578125
Iteration no. 68, lr = 0.0001, batch_loss = 0.27549817444585, train_err = 0.10546875
Iteration no. 69, lr = 0.0001, batch_loss = 0.28450101499701, train_err = 0.130859375
Iteration no. 70, lr = 0.0001, batch_loss = 0.28815698907169, train_err = 0.1171875
Iteration no. 71, lr = 0.0001, batch_loss = 0.27297500891427, train_err = 0.115234375
Iteration no. 72, lr = 0.0001, batch_loss = 0.30309086421982, train_err = 0.126953125
Iteration no. 73, lr = 0.0001, batch_loss = 0.25996681379218, train_err = 0.103515625
Iteration no. 74, lr = 0.0001, batch_loss = 0.25058660918057, train_err = 0.10546875
Iteration no. 75, lr = 0.0001, batch_loss = 0.29420206544611, train_err = 0.123046875
Iteration no. 76, lr = 0.0001, batch_loss = 0.28908417911242, train_err = 0.140625
Iteration no. 77, lr = 0.0001, batch_loss = 0.25322378228069, train_err = 0.1171875
Iteration no. 78, lr = 0.0001, batch_loss = 0.28937522157063, train_err = 0.13671875
Iteration no. 79, lr = 0.0001, batch_loss = 0.25250535102762, train_err = 0.115234375
Iteration no. 80, lr = 0.0001, batch_loss = 0.2943260166029, train_err = 0.134765625
Iteration no. 81, lr = 0.0001, batch_loss = 0.25465207489261, train_err = 0.107421875
Iteration no. 82, lr = 0.0001, batch_loss = 0.29280242022102, train_err = 0.140625
Iteration no. 83, lr = 0.0001, batch_loss = 0.28515568042321, train_err = 0.130859375
Iteration no. 84, lr = 0.0001, batch_loss = 0.27721237696158, train_err = 0.1328125
Iteration no. 85, lr = 0.0001, batch_loss = 0.25867174570334, train_err = 0.10546875
Iteration no. 86, lr = 0.0001, batch_loss = 0.2991675303891, train_err = 0.150390625
Iteration no. 87, lr = 0.0001, batch_loss = 0.28448466875399, train_err = 0.1171875
Iteration no. 88, lr = 0.0001, batch_loss = 0.28765974961438, train_err = 0.14453125
Iteration no. 89, lr = 0.0001, batch_loss = 0.26527019209874, train_err = 0.125
Iteration no. 90, lr = 0.0001, batch_loss = 0.27347800797592, train_err = 0.123046875
Iteration no. 91, lr = 0.0001, batch_loss = 0.28408019180781, train_err = 0.12109375
Iteration no. 92, lr = 0.0001, batch_loss = 0.2272974195206, train_err = 0.1015625
Iteration no. 93, lr = 0.0001, batch_loss = 0.30344752242435, train_err = 0.130859375
Iteration no. 94, lr = 0.0001, batch_loss = 0.26687302321515, train_err = 0.115234375
Iteration no. 95, lr = 0.0001, batch_loss = 0.31712925429338, train_err = 0.140625
Iteration no. 96, lr = 0.0001, batch_loss = 0.26647623823892, train_err = 0.1171875
Iteration no. 97, lr = 0.0001, batch_loss = 0.27871621033513, train_err = 0.1171875
Iteration no. 98, lr = 0.0001, batch_loss = 0.25181952171946, train_err = 0.103515625
Iteration no. 99, lr = 0.0001, batch_loss = 0.29903126788522, train_err = 0.1484375
Iteration no. 100, lr = 0.0001, batch_loss = 0.27038830898567, train_err = 0.115234375
Testing... test_loss = 0.23643069169588, test_pred_err = 0.098
Snapshotting A_model... done
Iteration no. 101, lr = 7e-05, batch_loss = 0.24596838995796, train_err = 0.099609375
Iteration no. 102, lr = 7e-05, batch_loss = 0.31679400884554, train_err = 0.140625
Iteration no. 103, lr = 7e-05, batch_loss = 0.26963113033794, train_err = 0.12109375
Iteration no. 104, lr = 7e-05, batch_loss = 0.26258803578713, train_err = 0.11328125
Iteration no. 105, lr = 7e-05, batch_loss = 0.28970815157763, train_err = 0.126953125
Iteration no. 106, lr = 7e-05, batch_loss = 0.2942331572415, train_err = 0.125
Iteration no. 107, lr = 7e-05, batch_loss = 0.24268470621974, train_err = 0.11328125
Iteration no. 108, lr = 7e-05, batch_loss = 0.24818918260883, train_err = 0.09765625
Iteration no. 109, lr = 7e-05, batch_loss = 0.23811895252477, train_err = 0.09765625
Iteration no. 110, lr = 7e-05, batch_loss = 0.22942701420809, train_err = 0.095703125
Iteration no. 111, lr = 7e-05, batch_loss = 0.26393662830822, train_err = 0.123046875
Iteration no. 112, lr = 7e-05, batch_loss = 0.27585267851004, train_err = 0.138671875
Iteration no. 113, lr = 7e-05, batch_loss = 0.27950734850826, train_err = 0.1171875
Iteration no. 114, lr = 7e-05, batch_loss = 0.26144892809747, train_err = 0.111328125
Iteration no. 115, lr = 7e-05, batch_loss = 0.24778443523584, train_err = 0.103515625
Iteration no. 116, lr = 7e-05, batch_loss = 0.24366440830999, train_err = 0.11328125
Iteration no. 117, lr = 7e-05, batch_loss = 0.30549410331169, train_err = 0.140625
Iteration no. 118, lr = 7e-05, batch_loss = 0.28456801180914, train_err = 0.119140625
Iteration no. 119, lr = 7e-05, batch_loss = 0.31158426562134, train_err = 0.13671875
Iteration no. 120, lr = 7e-05, batch_loss = 0.27757295860092, train_err = 0.1171875
Iteration no. 121, lr = 7e-05, batch_loss = 0.26497314585761, train_err = 0.123046875
Iteration no. 122, lr = 7e-05, batch_loss = 0.24090612326688, train_err = 0.09375
Iteration no. 123, lr = 7e-05, batch_loss = 0.25240978616811, train_err = 0.115234375
Iteration no. 124, lr = 7e-05, batch_loss = 0.31370692020475, train_err = 0.123046875
Iteration no. 125, lr = 7e-05, batch_loss = 0.23357843778206, train_err = 0.1015625
Iteration no. 126, lr = 7e-05, batch_loss = 0.25822106997143, train_err = 0.10546875
Iteration no. 127, lr = 7e-05, batch_loss = 0.23420527631497, train_err = 0.09765625
Iteration no. 128, lr = 7e-05, batch_loss = 0.28288355771939, train_err = 0.12890625
Iteration no. 129, lr = 7e-05, batch_loss = 0.2427282916258, train_err = 0.099609375
Iteration no. 130, lr = 7e-05, batch_loss = 0.25070629020399, train_err = 0.11328125
Iteration no. 131, lr = 7e-05, batch_loss = 0.28598159918663, train_err = 0.130859375
Iteration no. 132, lr = 7e-05, batch_loss = 0.25923890875731, train_err = 0.10546875
Iteration no. 133, lr = 7e-05, batch_loss = 0.23171304378421, train_err = 0.091796875
Iteration no. 134, lr = 7e-05, batch_loss = 0.23660650075517, train_err = 0.083984375
Iteration no. 135, lr = 7e-05, batch_loss = 0.26186954167072, train_err = 0.119140625
Iteration no. 136, lr = 7e-05, batch_loss = 0.25742419616223, train_err = 0.111328125
Iteration no. 137, lr = 7e-05, batch_loss = 0.27846484097102, train_err = 0.115234375
Iteration no. 138, lr = 7e-05, batch_loss = 0.28406083882879, train_err = 0.126953125
Iteration no. 139, lr = 7e-05, batch_loss = 0.25613652488109, train_err = 0.103515625
Iteration no. 140, lr = 7e-05, batch_loss = 0.25425299983518, train_err = 0.095703125
Iteration no. 141, lr = 7e-05, batch_loss = 0.23483945951885, train_err = 0.115234375
Iteration no. 142, lr = 7e-05, batch_loss = 0.26794071726093, train_err = 0.109375
Iteration no. 143, lr = 7e-05, batch_loss = 0.29607412421297, train_err = 0.12109375
Iteration no. 144, lr = 7e-05, batch_loss = 0.23248568276248, train_err = 0.087890625
Iteration no. 145, lr = 7e-05, batch_loss = 0.27374760937227, train_err = 0.125
Iteration no. 146, lr = 7e-05, batch_loss = 0.29453431359439, train_err = 0.126953125
Iteration no. 147, lr = 7e-05, batch_loss = 0.2436994412287, train_err = 0.103515625
Iteration no. 148, lr = 7e-05, batch_loss = 0.21595109088891, train_err = 0.087890625
Iteration no. 149, lr = 7e-05, batch_loss = 0.257072436953, train_err = 0.099609375
Iteration no. 150, lr = 7e-05, batch_loss = 0.24928092705268, train_err = 0.10546875
Testing... test_loss = 0.26121097056359, test_pred_err = 0.114
Iteration no. 151, lr = 7e-05, batch_loss = 0.26337264782367, train_err = 0.12109375
Iteration no. 152, lr = 7e-05, batch_loss = 0.22759938339447, train_err = 0.09765625
Iteration no. 153, lr = 7e-05, batch_loss = 0.23934346273925, train_err = 0.111328125
Iteration no. 154, lr = 7e-05, batch_loss = 0.27111462017415, train_err = 0.11328125
Iteration no. 155, lr = 7e-05, batch_loss = 0.27045657717667, train_err = 0.103515625
Iteration no. 156, lr = 7e-05, batch_loss = 0.25105992314213, train_err = 0.1171875
Iteration no. 157, lr = 7e-05, batch_loss = 0.24557054637259, train_err = 0.1015625
Iteration no. 158, lr = 7e-05, batch_loss = 0.25074804371861, train_err = 0.123046875
Iteration no. 159, lr = 7e-05, batch_loss = 0.3182749960541, train_err = 0.12890625
Iteration no. 160, lr = 7e-05, batch_loss = 0.28498023649577, train_err = 0.123046875
Iteration no. 161, lr = 7e-05, batch_loss = 0.23398294164353, train_err = 0.076171875
Iteration no. 162, lr = 7e-05, batch_loss = 0.29162658559589, train_err = 0.12109375
Iteration no. 163, lr = 7e-05, batch_loss = 0.249356107868, train_err = 0.1015625
Iteration no. 164, lr = 7e-05, batch_loss = 0.24881514954779, train_err = 0.10546875
Iteration no. 165, lr = 7e-05, batch_loss = 0.27049824677152, train_err = 0.115234375
Iteration no. 166, lr = 7e-05, batch_loss = 0.22189986038222, train_err = 0.09765625
Iteration no. 167, lr = 7e-05, batch_loss = 0.33589143431621, train_err = 0.13671875
Iteration no. 168, lr = 7e-05, batch_loss = 0.2368311910291, train_err = 0.08984375
Iteration no. 169, lr = 7e-05, batch_loss = 0.23176800207466, train_err = 0.091796875
Iteration no. 170, lr = 7e-05, batch_loss = 0.26477873610222, train_err = 0.1015625
Iteration no. 171, lr = 7e-05, batch_loss = 0.27590418925412, train_err = 0.11328125
Iteration no. 172, lr = 7e-05, batch_loss = 0.24173782192485, train_err = 0.1015625
Iteration no. 173, lr = 7e-05, batch_loss = 0.23396785640216, train_err = 0.091796875
Iteration no. 174, lr = 7e-05, batch_loss = 0.20944317222921, train_err = 0.087890625
Iteration no. 175, lr = 7e-05, batch_loss = 0.23561846161496, train_err = 0.09765625
Iteration no. 176, lr = 7e-05, batch_loss = 0.24170493622001, train_err = 0.095703125
Iteration no. 177, lr = 7e-05, batch_loss = 0.28157316126068, train_err = 0.130859375
Iteration no. 178, lr = 7e-05, batch_loss = 0.21274434377205, train_err = 0.083984375
Iteration no. 179, lr = 7e-05, batch_loss = 0.25778954884081, train_err = 0.123046875
Iteration no. 180, lr = 7e-05, batch_loss = 0.24759864502921, train_err = 0.10546875
Iteration no. 181, lr = 7e-05, batch_loss = 0.24477082267684, train_err = 0.111328125
Iteration no. 182, lr = 7e-05, batch_loss = 0.31137108513971, train_err = 0.12109375
Iteration no. 183, lr = 7e-05, batch_loss = 0.24402745860867, train_err = 0.107421875
Iteration no. 184, lr = 7e-05, batch_loss = 0.22259405087258, train_err = 0.0859375
Iteration no. 185, lr = 7e-05, batch_loss = 0.2586336398212, train_err = 0.103515625
Iteration no. 186, lr = 7e-05, batch_loss = 0.24808257188995, train_err = 0.099609375
Iteration no. 187, lr = 7e-05, batch_loss = 0.23200017811285, train_err = 0.087890625
Iteration no. 188, lr = 7e-05, batch_loss = 0.25337594279967, train_err = 0.11328125
Iteration no. 189, lr = 7e-05, batch_loss = 0.24310419795856, train_err = 0.09765625
Iteration no. 190, lr = 7e-05, batch_loss = 0.27599324446691, train_err = 0.107421875
Iteration no. 191, lr = 7e-05, batch_loss = 0.19601273130421, train_err = 0.087890625
Iteration no. 192, lr = 7e-05, batch_loss = 0.26701810354317, train_err = 0.12109375
Iteration no. 193, lr = 7e-05, batch_loss = 0.24894022681754, train_err = 0.115234375
Iteration no. 194, lr = 7e-05, batch_loss = 0.2124516944679, train_err = 0.091796875
Iteration no. 195, lr = 7e-05, batch_loss = 0.27442707261107, train_err = 0.119140625
Iteration no. 196, lr = 7e-05, batch_loss = 0.28369738614564, train_err = 0.111328125
Iteration no. 197, lr = 7e-05, batch_loss = 0.23353280455239, train_err = 0.111328125
Iteration no. 198, lr = 7e-05, batch_loss = 0.23057578050609, train_err = 0.099609375
Iteration no. 199, lr = 7e-05, batch_loss = 0.22639384923102, train_err = 0.09375
Iteration no. 200, lr = 7e-05, batch_loss = 0.21124488963331, train_err = 0.080078125
Testing... test_loss = 0.25491462683722, test_pred_err = 0.114
Snapshotting A_model... done
Iteration no. 201, lr = 4.9e-05, batch_loss = 0.27061718336296, train_err = 0.123046875
Iteration no. 202, lr = 4.9e-05, batch_loss = 0.22430052120914, train_err = 0.09765625
Iteration no. 203, lr = 4.9e-05, batch_loss = 0.25666557875552, train_err = 0.111328125
