Loading pretrained model... done
Creating Full model... done
Reading features and labels... done
Training with snapshotting disabled... 
Testing... test_loss = 1.1576084504802, test_pred_err = 0.378
Iteration no. 1, lr = 0.02, batch_loss = 0.83736277258459, train_err = 0.275390625
Iteration no. 2, lr = 0.02, batch_loss = 15.434515701475, train_err = 0.55859375
Iteration no. 3, lr = 0.02, batch_loss = 14.2472452629, train_err = 0.515625
Iteration no. 4, lr = 0.02, batch_loss = 12.844107471857, train_err = 0.46484375
Iteration no. 5, lr = 0.02, batch_loss = 11.926671223867, train_err = 0.431640625
Iteration no. 6, lr = 0.02, batch_loss = 13.32980901491, train_err = 0.482421875
Iteration no. 7, lr = 0.02, batch_loss = 14.301212101017, train_err = 0.517578125
Iteration no. 8, lr = 0.02, batch_loss = 12.952041148091, train_err = 0.46875
Iteration no. 9, lr = 0.02, batch_loss = 13.815510557857, train_err = 0.5
Iteration no. 10, lr = 0.02, batch_loss = 14.2472452629, train_err = 0.515625
Iteration no. 11, lr = 0.02, batch_loss = 14.894847320305, train_err = 0.5390625
Iteration no. 12, lr = 0.02, batch_loss = 14.517079453486, train_err = 0.525390625
Iteration no. 13, lr = 0.02, batch_loss = 12.952041147954, train_err = 0.46875
Iteration no. 14, lr = 0.02, batch_loss = 13.491709529262, train_err = 0.48828125
Iteration no. 15, lr = 0.02, batch_loss = 13.545676367379, train_err = 0.490234375
Iteration no. 16, lr = 0.02, batch_loss = 12.898074309974, train_err = 0.466796875
Iteration no. 17, lr = 0.02, batch_loss = 13.653610043613, train_err = 0.494140625
Iteration no. 18, lr = 0.02, batch_loss = 12.628240119389, train_err = 0.45703125
Iteration no. 19, lr = 0.02, batch_loss = 13.383775853027, train_err = 0.484375
Iteration no. 20, lr = 0.02, batch_loss = 14.139311586666, train_err = 0.51171875
Iteration no. 21, lr = 0.02, batch_loss = 14.031377910432, train_err = 0.5078125
Iteration no. 22, lr = 0.02, batch_loss = 13.275842176793, train_err = 0.48046875
Iteration no. 23, lr = 0.02, batch_loss = 13.977411072315, train_err = 0.505859375
Iteration no. 24, lr = 0.02, batch_loss = 14.948814158422, train_err = 0.541015625
Iteration no. 25, lr = 0.02, batch_loss = 13.383775853027, train_err = 0.484375
Iteration no. 26, lr = 0.02, batch_loss = 12.628240119389, train_err = 0.45703125
Iteration no. 27, lr = 0.02, batch_loss = 12.844107471857, train_err = 0.46484375
Iteration no. 28, lr = 0.02, batch_loss = 13.491709529262, train_err = 0.48828125
Iteration no. 29, lr = 0.02, batch_loss = 14.247245250299, train_err = 0.515625
Iteration no. 30, lr = 0.02, batch_loss = 15.16468151089, train_err = 0.548828125
Iteration no. 31, lr = 0.02, batch_loss = 14.085344748549, train_err = 0.509765625
Iteration no. 32, lr = 0.02, batch_loss = 13.707576879301, train_err = 0.49609375
Iteration no. 33, lr = 0.02, batch_loss = 14.085344748549, train_err = 0.509765625
Iteration no. 34, lr = 0.02, batch_loss = 13.437742691144, train_err = 0.486328125
Iteration no. 35, lr = 0.02, batch_loss = 14.732946805953, train_err = 0.533203125
Iteration no. 36, lr = 0.02, batch_loss = 13.545676367379, train_err = 0.490234375
Iteration no. 37, lr = 0.02, batch_loss = 14.571046291603, train_err = 0.52734375
Iteration no. 38, lr = 0.02, batch_loss = 14.355178939134, train_err = 0.51953125
Iteration no. 39, lr = 0.02, batch_loss = 14.571046291603, train_err = 0.52734375
Iteration no. 40, lr = 0.02, batch_loss = 13.113941662442, train_err = 0.474609375
Iteration no. 41, lr = 0.02, batch_loss = 14.031377910432, train_err = 0.5078125
Iteration no. 42, lr = 0.02, batch_loss = 13.653610043613, train_err = 0.494140625
Iteration no. 43, lr = 0.02, batch_loss = 13.923444234198, train_err = 0.50390625
Iteration no. 44, lr = 0.02, batch_loss = 14.517079448521, train_err = 0.525390625
Iteration no. 45, lr = 0.02, batch_loss = 14.840880482188, train_err = 0.537109375
Iteration no. 46, lr = 0.02, batch_loss = 14.948814158422, train_err = 0.541015625
Iteration no. 47, lr = 0.02, batch_loss = 13.923444234198, train_err = 0.50390625
Iteration no. 48, lr = 0.02, batch_loss = 12.898074309974, train_err = 0.466796875
Iteration no. 49, lr = 0.02, batch_loss = 13.329809014909, train_err = 0.482421875
Iteration no. 50, lr = 0.02, batch_loss = 15.056747834656, train_err = 0.544921875
Testing... test_loss = 13.815510397067, test_pred_err = 0.5
Iteration no. 51, lr = 0.02, batch_loss = 14.085344748549, train_err = 0.509765625
Iteration no. 52, lr = 0.02, batch_loss = 13.653610043613, train_err = 0.494140625
Iteration no. 53, lr = 0.02, batch_loss = 13.32980901491, train_err = 0.482421875
Iteration no. 54, lr = 0.02, batch_loss = 13.599643205496, train_err = 0.4921875
Iteration no. 55, lr = 0.02, batch_loss = 14.2472452629, train_err = 0.515625
Iteration no. 56, lr = 0.02, batch_loss = 14.193278424783, train_err = 0.513671875
Iteration no. 57, lr = 0.02, batch_loss = 14.301212101017, train_err = 0.517578125
Iteration no. 58, lr = 0.02, batch_loss = 13.491709529262, train_err = 0.48828125
Iteration no. 59, lr = 0.02, batch_loss = 14.517079453486, train_err = 0.525390625
Iteration no. 60, lr = 0.02, batch_loss = 13.70757688173, train_err = 0.49609375
Iteration no. 61, lr = 0.02, batch_loss = 13.815510557964, train_err = 0.5
Iteration no. 62, lr = 0.02, batch_loss = 13.599643205493, train_err = 0.4921875
Iteration no. 63, lr = 0.02, batch_loss = 14.085344748549, train_err = 0.509765625
Iteration no. 64, lr = 0.02, batch_loss = 13.275842176793, train_err = 0.48046875
Iteration no. 65, lr = 0.02, batch_loss = 14.2472452629, train_err = 0.515625
Iteration no. 66, lr = 0.02, batch_loss = 13.815510557964, train_err = 0.5
Iteration no. 67, lr = 0.02, batch_loss = 13.545676367379, train_err = 0.490234375
Iteration no. 68, lr = 0.02, batch_loss = 14.301212101017, train_err = 0.517578125
Iteration no. 69, lr = 0.02, batch_loss = 14.193278424783, train_err = 0.513671875
Iteration no. 70, lr = 0.02, batch_loss = 14.193278424783, train_err = 0.513671875
Iteration no. 71, lr = 0.02, batch_loss = 12.844107471857, train_err = 0.46484375
Iteration no. 72, lr = 0.02, batch_loss = 14.139311586666, train_err = 0.51171875
Iteration no. 73, lr = 0.02, batch_loss = 13.599643205496, train_err = 0.4921875
Iteration no. 74, lr = 0.02, batch_loss = 12.952041148091, train_err = 0.46875
Iteration no. 75, lr = 0.02, batch_loss = 14.463112615368, train_err = 0.5234375
Iteration no. 76, lr = 0.02, batch_loss = 14.031377910432, train_err = 0.5078125
Iteration no. 77, lr = 0.02, batch_loss = 13.70757688173, train_err = 0.49609375
Iteration no. 78, lr = 0.02, batch_loss = 13.059974824325, train_err = 0.47265625
Iteration no. 79, lr = 0.02, batch_loss = 13.437742691145, train_err = 0.486328125
Iteration no. 80, lr = 0.02, batch_loss = 13.869477396081, train_err = 0.501953125
Iteration no. 81, lr = 0.02, batch_loss = 14.463112615368, train_err = 0.5234375
Iteration no. 82, lr = 0.02, batch_loss = 14.139311586666, train_err = 0.51171875
Iteration no. 83, lr = 0.02, batch_loss = 12.466339605038, train_err = 0.451171875
Iteration no. 84, lr = 0.02, batch_loss = 13.599643205496, train_err = 0.4921875
Iteration no. 85, lr = 0.02, batch_loss = 12.898074309974, train_err = 0.466796875
Iteration no. 86, lr = 0.02, batch_loss = 14.355178938706, train_err = 0.51953125
Iteration no. 87, lr = 0.02, batch_loss = 14.678979966986, train_err = 0.53125
Iteration no. 88, lr = 0.02, batch_loss = 13.545676367379, train_err = 0.490234375
Iteration no. 89, lr = 0.02, batch_loss = 13.113941662442, train_err = 0.474609375
Iteration no. 90, lr = 0.02, batch_loss = 14.355178939134, train_err = 0.51953125
Iteration no. 91, lr = 0.02, batch_loss = 13.059974824325, train_err = 0.47265625
Iteration no. 92, lr = 0.02, batch_loss = 15.110714672773, train_err = 0.546875
Iteration no. 93, lr = 0.02, batch_loss = 14.301212100865, train_err = 0.517578125
Iteration no. 94, lr = 0.02, batch_loss = 14.139311586666, train_err = 0.51171875
Iteration no. 95, lr = 0.02, batch_loss = 14.732946805954, train_err = 0.533203125
Iteration no. 96, lr = 0.02, batch_loss = 14.40914577725, train_err = 0.521484375
Iteration no. 97, lr = 0.02, batch_loss = 12.79014063374, train_err = 0.462890625
Iteration no. 98, lr = 0.02, batch_loss = 14.517079453486, train_err = 0.525390625
Iteration no. 99, lr = 0.02, batch_loss = 13.006007709501, train_err = 0.470703125
Iteration no. 100, lr = 0.02, batch_loss = 14.139311586666, train_err = 0.51171875
Testing... test_loss = 14.58911564564, test_pred_err = 0.528
